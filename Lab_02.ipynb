{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-09T13:37:07.332097200Z",
     "start_time": "2024-10-09T13:37:05.940091600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typy danych w ramce Dask:\n",
      "Kraj;Sprzedawca;Data zamowienia;idZamowienia;Utarg    string[pyarrow]\n",
      "kolumna1                                                      float64\n",
      "kolumna2                                                      float64\n",
      "kolumna3                                                      float64\n",
      "dtype: object\n",
      "Suma wartości w kolumnie 'kolumna1': 0.0\n",
      "Typy danych w ramce Dask z sample=1000:\n",
      "Kraj;Sprzedawca;Data zamowienia;idZamowienia;Utarg    string[pyarrow]\n",
      "kolumna1                                                      float64\n",
      "kolumna2                                                      float64\n",
      "kolumna3                                                      float64\n",
      "dtype: object\n",
      "Typy danych w ramce Dask z sample=5000:\n",
      "Kraj;Sprzedawca;Data zamowienia;idZamowienia;Utarg    string[pyarrow]\n",
      "kolumna1                                                      float64\n",
      "kolumna2                                                      float64\n",
      "kolumna3                                                      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "'''Zadanie 1'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "\n",
    "df = pd.read_csv('zamowienia.csv')\n",
    "\n",
    "df.loc[10:12, 'kolumna1'] = np.nan\n",
    "df.loc[15:17, 'kolumna2'] = np.nan\n",
    "df.loc[20:22, 'kolumna3'] = np.nan\n",
    "\n",
    "df.to_csv('zamowienia_missing.csv', index=False)\n",
    "\n",
    "ddf = dd.read_csv('zamowienia_missing.csv')\n",
    "\n",
    "print(\"Typy danych w ramce Dask:\")\n",
    "print(ddf.dtypes)\n",
    "\n",
    "result = ddf['kolumna1'].sum().compute()\n",
    "print(\"Suma wartości w kolumnie 'kolumna1':\", result)\n",
    "\n",
    "ddf_sample1 = dd.read_csv('zamowienia_missing.csv', sample=1000)\n",
    "ddf_sample2 = dd.read_csv('zamowienia_missing.csv', sample=5000)\n",
    "\n",
    "print(\"Typy danych w ramce Dask z sample=1000:\")\n",
    "print(ddf_sample1.dtypes)\n",
    "\n",
    "print(\"Typy danych w ramce Dask z sample=5000:\")\n",
    "print(ddf_sample2.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8787/status\n"
     ]
    }
   ],
   "source": [
    "'''Zadanie 2'''\n",
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "print(client.dashboard_link)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-09T13:37:09.185297800Z",
     "start_time": "2024-10-09T13:37:07.332097200Z"
    }
   },
   "id": "62ee4975a4cb3bce"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sid  sid_profile      post_id  profile_id                 date  \\\n",
      "0  28370919      3496776  BXdjjUlgcgq  2237947779  2017-08-06 20:06:57   \n",
      "1  13623950      3496776  BeyPed5hKj9  2237947779  2018-02-04 19:35:20   \n",
      "2  28370905      3496776  Bunhd1DFVAG  2237947779  2019-03-05 08:03:11   \n",
      "3  28370907      3496776  Bppi85gliQK  2237947779  2018-11-01 20:17:41   \n",
      "4  32170690      3496776  BuDfIyslzfw  2237947779  2019-02-19 08:10:11   \n",
      "\n",
      "   post_type                                        description  likes  \\\n",
      "0          2  Wreckloose! Deevalley bike park laps on the @i...     80   \n",
      "1          1  The dirty south was prime today. Top day with ...     86   \n",
      "2          1  Tech Tuesday. Been flat out on the tools. Got ...    168   \n",
      "3          1  On the tools, my favourite wheel builds @stans...    102   \n",
      "4          1  Solid effort on the bar turn.\\nFully turned.\\n...    145   \n",
      "\n",
      "   comments   username                                                bio  \\\n",
      "0         0  andylund_  Professional Bicycle technician, Intense Racin...   \n",
      "1         2  andylund_  Professional Bicycle technician, Intense Racin...   \n",
      "2         3  andylund_  Professional Bicycle technician, Intense Racin...   \n",
      "3         2  andylund_  Professional Bicycle technician, Intense Racin...   \n",
      "4         2  andylund_  Professional Bicycle technician, Intense Racin...   \n",
      "\n",
      "   following  followers  num_posts  is_business_account lang  \\\n",
      "0        520       1204        494                False   en   \n",
      "1        520       1204        494                False   en   \n",
      "2        520       1204        494                False   en   \n",
      "3        520       1204        494                False   en   \n",
      "4        520       1204        494                False   en   \n",
      "\n",
      "               category  \n",
      "0    travel_&_adventure  \n",
      "1  diaries_&_daily_life  \n",
      "2  science_&_technology  \n",
      "3  diaries_&_daily_life  \n",
      "4  diaries_&_daily_life  \n",
      "Czas załadowania danych: 1.60 sekundy\n"
     ]
    }
   ],
   "source": [
    "'''Zadanie 3'''\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "import time\n",
    "\n",
    "client = Client(memory_limit='16GB', n_workers=6, threads_per_worker=1)\n",
    "\n",
    "print(client)\n",
    "\n",
    "file_list = [f\"{str(i).zfill(4)}.parquet\" for i in range(15)]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df = dd.read_parquet(file_list, engine='pyarrow')\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Czas załadowania danych: {end_time - start_time:.2f} sekundy\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-09T13:37:12.487430900Z",
     "start_time": "2024-10-09T13:37:09.185297800Z"
    }
   },
   "id": "a2043a2b6f16f022"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 użytkowników z najwyższą liczbą like'ów:\n",
      "username\n",
      "lilireinhart     40375292\n",
      "instagram        29864166\n",
      "jamescharles     26067462\n",
      "lizakoshy        19217644\n",
      "elle             17494288\n",
      "433              16457870\n",
      "amandacerny      15019135\n",
      "saraalikhan95    14199489\n",
      "zkdlin           13799100\n",
      "akshaykumar      13352324\n",
      "Name: likes, dtype: int64\n",
      "Czas operacji: 3.51 sekundy\n"
     ]
    }
   ],
   "source": [
    "'''Zadanie 4'''\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "import time\n",
    "\n",
    "client = Client(memory_limit='16GB', n_workers=6, threads_per_worker=1)\n",
    "\n",
    "file_list = [f\"{str(i).zfill(4)}.parquet\" for i in range(15)]\n",
    "\n",
    "df = dd.read_parquet(file_list, engine='pyarrow')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "top_users = df.groupby('username')['likes'].sum().nlargest(10).compute()\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Top 10 użytkowników z najwyższą liczbą like'ów:\")\n",
    "print(top_users)\n",
    "print(f\"Czas operacji: {end_time - start_time:.2f} sekundy\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df['date'] = dd.to_datetime(df['date'])\n",
    "filtered_df = df[(df['date'] >= '2019-01-01') & (df['date'] < '2019-07-01')].compute()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Liczba rekordów za pierwsze półrocze 2019 roku: {len(filtered_df)}\")\n",
    "print(f\"Czas operacji: {end_time - start_time:.2f} sekundy\")\n",
    "\n",
    "print(filtered_df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-09T13:57:21.757610Z",
     "start_time": "2024-10-09T13:57:00.962922500Z"
    }
   },
   "id": "60e28be6433f3892"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas ładowania danych z określonymi typami: 0.05 sekundy\n",
      "Top 10 użytkowników z najwyższą liczbą like'ów:\n",
      "username\n",
      "lilireinhart     40375292\n",
      "instagram        29864166\n",
      "jamescharles     26067462\n",
      "lizakoshy        19217644\n",
      "elle             17494288\n",
      "433              16457870\n",
      "amandacerny      15019135\n",
      "saraalikhan95    14199489\n",
      "zkdlin           13799100\n",
      "akshaykumar      13352324\n",
      "Name: likes, dtype: int64\n",
      "Czas operacji: 3.36 sekundy\n",
      "Liczba rekordów za pierwsze półrocze 2019 roku: 10890703\n",
      "Czas operacji: 67.12 sekundy\n",
      "        sid  sid_profile      post_id  profile_id                 date  \\\n",
      "2  28370905      3496776  Bunhd1DFVAG  2237947779  2019-03-05 08:03:11   \n",
      "4  32170690      3496776  BuDfIyslzfw  2237947779  2019-02-19 08:10:11   \n",
      "5  14315358      3496776  BxJsMDpA2yH  2237947779  2019-05-07 08:33:51   \n",
      "6   8304346      3496776  Bt5LFpZlm3z  2237947779  2019-02-15 08:02:35   \n",
      "7  14315346      3496776  BxZIzaQhS-o  2237947779  2019-05-13 08:32:30   \n",
      "\n",
      "   post_type                                        description  likes  \\\n",
      "2          1  Tech Tuesday. Been flat out on the tools. Got ...    168   \n",
      "4          1  Solid effort on the bar turn.\\nFully turned.\\n...    145   \n",
      "5          1  Annual springtime flora picture.\\nTurn bars in...    124   \n",
      "6          1  Laps in spring like conditions. Getting these ...    150   \n",
      "7          1  Cheers Scotland 🏴󠁧󠁢󠁳󠁣󠁴󠁿 See you in a few weeks...    166   \n",
      "\n",
      "   comments   username                                                bio  \\\n",
      "2         3  andylund_  Professional Bicycle technician, Intense Racin...   \n",
      "4         2  andylund_  Professional Bicycle technician, Intense Racin...   \n",
      "5         2  andylund_  Professional Bicycle technician, Intense Racin...   \n",
      "6         3  andylund_  Professional Bicycle technician, Intense Racin...   \n",
      "7         2  andylund_  Professional Bicycle technician, Intense Racin...   \n",
      "\n",
      "   following  followers  num_posts  is_business_account lang  \\\n",
      "2        520       1204        494                False   en   \n",
      "4        520       1204        494                False   en   \n",
      "5        520       1204        494                False   en   \n",
      "6        520       1204        494                False   en   \n",
      "7        520       1204        494                False   en   \n",
      "\n",
      "               category  \n",
      "2  science_&_technology  \n",
      "4  diaries_&_daily_life  \n",
      "5        arts_&_culture  \n",
      "6                sports  \n",
      "7                sports  \n"
     ]
    }
   ],
   "source": [
    "'''Zadanie 5'''\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "import time\n",
    "\n",
    "client = Client(memory_limit='16GB', n_workers=6, threads_per_worker=1)\n",
    "\n",
    "file_list = [f\"{str(i).zfill(4)}.parquet\" for i in range(15)]\n",
    "\n",
    "dtypes = {\n",
    "    'username': 'string',\n",
    "    'likes': 'int',\n",
    "    'date': 'datetime64[ns]'\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "df = dd.read_parquet(file_list, engine='pyarrow', dtype=dtypes)\n",
    "end_time = time.time()\n",
    "print(f\"Czas ładowania danych z określonymi typami: {end_time - start_time:.2f} sekundy\")\n",
    "\n",
    "start_time = time.time()\n",
    "top_users = df.groupby('username')['likes'].sum().nlargest(10).compute()\n",
    "end_time = time.time()\n",
    "print(\"Top 10 użytkowników z najwyższą liczbą like'ów:\")\n",
    "print(top_users)\n",
    "print(f\"Czas operacji: {end_time - start_time:.2f} sekundy\")\n",
    "\n",
    "start_time = time.time()\n",
    "filtered_df = df[(df['date'] >= '2019-01-01') & (df['date'] < '2019-07-01')].compute()\n",
    "end_time = time.time()\n",
    "print(f\"Liczba rekordów za pierwsze półrocze 2019 roku: {len(filtered_df)}\")\n",
    "print(f\"Czas operacji: {end_time - start_time:.2f} sekundy\")\n",
    "\n",
    "print(filtered_df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-09T13:43:33.120566Z",
     "start_time": "2024-10-09T13:42:17.148835300Z"
    }
   },
   "id": "fee8cd1086beb9d8"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wnioski:\n",
      "Podział na chunki (1000, 1000) - średni czas: 4.4321 sekundy\n",
      "Podział na chunki (2000, 2000) - średni czas: 3.9757 sekundy\n",
      "Podział na chunki (5000, 5000) - średni czas: 3.7703 sekundy\n",
      "Podział na chunki (10000, 10000) - średni czas: 2.4939 sekundy\n"
     ]
    }
   ],
   "source": [
    "'''Zadanie 6'''\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "np_array = np.random.random(size=(10000, 10000))\n",
    "\n",
    "def measure_time(chunks):\n",
    "    darr = da.from_array(np_array, chunks=chunks)\n",
    "    times = []\n",
    "    for _ in range(10):\n",
    "        start_time = time.time()\n",
    "        mean_value = darr.mean().compute()\n",
    "        end_time = time.time()\n",
    "        times.append(end_time - start_time)\n",
    "    return np.mean(times), mean_value\n",
    "\n",
    "chunk_sizes = [(1000, 1000), (2000, 2000), (5000, 5000), (10000, 10000)]\n",
    "results = {}\n",
    "\n",
    "for chunks in chunk_sizes:\n",
    "    avg_time, mean_value = measure_time(chunks)\n",
    "    results[chunks] = (avg_time, mean_value)\n",
    "    print(f\"Chunks: {chunks}, Average Time: {avg_time:.4f} seconds, Mean: {mean_value}\")\n",
    "\n",
    "print(\"\\nWnioski:\")\n",
    "for chunks, (avg_time, mean_value) in results.items():\n",
    "    print(f\"Podział na chunki {chunks} - średni czas: {avg_time:.4f} sekundy\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-09T13:41:53.330207500Z",
     "start_time": "2024-10-09T13:39:24.498348200Z"
    }
   },
   "id": "11a63fc57e3b7e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "64c952500def91c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
